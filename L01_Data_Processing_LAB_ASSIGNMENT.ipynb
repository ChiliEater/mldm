{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiliEater/mldm/blob/main/L01_Data_Processing_LAB_ASSIGNMENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8bPV9aEwTKC8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jFHJbjkfeepf"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 0x0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykbI8UnR6PsU"
      },
      "source": [
        "# TASK 1 (2 Points): \n",
        "\n",
        "We work with the \"Wine Recognition\" dataset. You can read more about this dataset at [https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset).\n",
        "\n",
        "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators.\n",
        "The data is loaded below and split into `data` and `target`. `data` is a `Dataframe` that contains the result of the chemical analysis while `target` contains an integer representing the wine cultivator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "em6VCOuE6MRU"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "(data, target) = load_wine(return_X_y=True, as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HJoAuMNR6MgM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d15bc35f-8e83-4284-fb10-26e1c1391f4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "173                          1.74    740.0  \n",
              "174                          1.56    750.0  \n",
              "175                          1.56    835.0  \n",
              "176                          1.62    840.0  \n",
              "177                          1.60    560.0  \n",
              "\n",
              "[178 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29beb050-2385-42f0-9b5f-0df406721198\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29beb050-2385-42f0-9b5f-0df406721198')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29beb050-2385-42f0-9b5f-0df406721198 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29beb050-2385-42f0-9b5f-0df406721198');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data\n",
        "# Test 123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xrsPKm3w6Mi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d0d5e8-d6ff-4098-cf22-c6a7eb92a70d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "173    2\n",
              "174    2\n",
              "175    2\n",
              "176    2\n",
              "177    2\n",
              "Name: target, Length: 178, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3W5r6Se8kXW"
      },
      "source": [
        "Next, the data is split into training data and testing data.\n",
        "The training data is used to train the model while the testing data is used to evaluate the model on different data than it was trained for. You will learn later in the course why this is necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m1w8dDgw6MoO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_eeYvZc-f_n"
      },
      "source": [
        "\n",
        "In the following, we define functions to classify the data. We use a [Decision Tree Classifier](https://scikit-learn.org/stable/modules/tree.html#tree) and a [Support Vector Classifier](https://scikit-learn.org/stable/modules/svm.html#svm-classification). You will learn later in the course how these classifiers work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pvm_zBOe-e_X"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def run_classifier(clf, X_train, y_train, X_test, y_test):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_test_predicted = clf.predict(X_test)\n",
        "  return accuracy_score(y_test, y_test_predicted)\n",
        "\n",
        "\n",
        "def run_decision_tree(X_train, y_train, X_test, y_test):\n",
        "  clf = DecisionTreeClassifier(random_state=0)\n",
        "  accuracy = run_classifier(clf, X_train, y_train, X_test, y_test)\n",
        "  print(\"The accuracy of the Decision Tree classifier is\", accuracy)\n",
        "\n",
        "def run_svc(X_train, y_train, X_test, y_test):\n",
        "  clf = SVC(random_state=0)\n",
        "  accuracy = run_classifier(clf, X_train, y_train, X_test, y_test)\n",
        "  print(\"The accuracy of the Support Vector classifier is\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1MS2D8LAMpD"
      },
      "source": [
        "### Task 1a: Classify the data\n",
        "\n",
        "Classify the data by calling the two functions `run_decision_tree` and `run_svc`.\n",
        "Which classifier works better (i.e. achieves the higher accuracy)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5ToW8fx4ANZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782eeb9b-0e95-4f2e-8345-f3b2ff729f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the Decision Tree classifier is 0.9661016949152542\n",
            "The accuracy of the Support Vector classifier is 0.711864406779661\n",
            "Decision tree has higher accuracy\n"
          ]
        }
      ],
      "source": [
        "run_decision_tree(X_train, y_train, X_test, y_test)\n",
        "run_svc(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"Decision tree has higher accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbM8OUZFBRGH"
      },
      "source": [
        "### Task 1b: Normalize the data with mean and standard deviation\n",
        "\n",
        "Normalize the training and testing data using the following formula:\n",
        "\n",
        "$$X_{normalized} = \\frac{X-\\mu_X}{\\sigma_X}$$\n",
        "\n",
        "Calculate the mean and standard deviation __on the training data__ only (also when you normalize the testing dataset).\n",
        "\n",
        "`Pandas` provides built-in functions to calculate the average and the standard deviation. For example, `X_train.mean()` returns the average value per feature in the training dataset while `X_train.std()` returns the standard deviation per feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K0qkP9TqBRft"
      },
      "outputs": [],
      "source": [
        "X_norm = (X_train - X_train.mean()) / X_train.std()\n",
        "X_test_norm = (X_test - X_train.mean()) / X_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fNuBgC6BSFt"
      },
      "source": [
        "Call the two classification functions again with the normalized data and report the changes in accuracy. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TFg6WbmgBShk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69e9a8d-8e3c-4cd7-d363-2e060f67efb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the Decision Tree classifier is 0.9661016949152542\n",
            "The accuracy of the Support Vector classifier is 0.9830508474576272\n",
            "Support Vector has higher accuracy\n"
          ]
        }
      ],
      "source": [
        "run_decision_tree(X_norm, y_train, X_test_norm, y_test)\n",
        "run_svc(X_norm, y_train, X_test_norm, y_test)\n",
        "\n",
        "print(\"Support Vector has higher accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_1EVF-TBS7v"
      },
      "source": [
        "### Task 1c: Repeat Task 1b with min-max Normalization\n",
        "\n",
        "Repeat the task 1b but use the following formula to normalize tha data:\n",
        "\n",
        "$$X_{normalized} = \\frac{X-X_{min}}{X_{max} - X_{min}}$$\n",
        "\n",
        "Again, calculate the maximum and minimum __on the training data__ only (also when you normalize the testing dataset) and use the built-in function `X_train.min()` resp. `X_train.max()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i25XenppJ7gf"
      },
      "outputs": [],
      "source": [
        "X_minmax = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
        "X_test_minmax = (X_test - X_train.min()) / (X_train.max() - X_train.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIy0ECbTJ7gq"
      },
      "source": [
        "Call the two classification functions again with the normalized data and report the changes in accuracy. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "99uuR7ngJ7gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a75564-0d83-434b-c083-f4c065c8b2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the Decision Tree classifier is 0.9661016949152542\n",
            "The accuracy of the Support Vector classifier is 0.9830508474576272\n",
            "DT is slightly less accurate\n"
          ]
        }
      ],
      "source": [
        "run_decision_tree(X_minmax, y_train, X_test_minmax, y_test)\n",
        "run_svc(X_minmax, y_train, X_test_minmax, y_test)\n",
        "\n",
        "print(\"DT is slightly less accurate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_i1aBh6KnWw"
      },
      "source": [
        "## ðŸ“¢ **HAND-IN** ðŸ“¢: Report on Moodle whether you solved this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7I1RBjQK7Ly"
      },
      "source": [
        "---\n",
        "# TASK 2 (2 Points): \n",
        "\n",
        "In Task 1 we clearly saw that normalization improves the result for Support Vector Classifiers but not for Decision Trees. You will learn later in the course why Decision Trees don't need normalization.\n",
        "\n",
        "However, to better understand the influence of normalization, we will plot the data with and without normalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "w9qp3e4nBTPK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"ticks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnF26SbCNCRS"
      },
      "source": [
        "### Task 2a: Plot the unnormalized data\n",
        "\n",
        "For simplicity, we only consider only the columns `alcohol` and `malic_acid` from the training dataset.\n",
        "\n",
        "Create a [Scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) from the corresponding training data mentioned below with the attribute `alcohol` on the `x`-axis and `malic_acid` on the `y`-axis.\n",
        "\n",
        "Plot the un-normalized data `X_train` as well as the two normalized versions from Exercise 1 in the same plot and describe what happens.\n",
        "\n",
        "__Hint:__ To visualize the data distributions in the same plot just call `sns.scatterplot` three times within the same code-cell. Add a 'label' argument to differentiate the data distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-lc07hbiOvYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ffbb4a04-e627-47ef-d8dc-1cfe627c7f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minmax groups the data very tightly in contrast to regular normalisation which mostly just moves all the points\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.scatterplot(data=X_train, x=\"alcohol\", y=\"malic_acid\", label=\"Raw\")\n",
        "sns.scatterplot(data=X_norm, x=\"alcohol\", y=\"malic_acid\", label=\"Normalised\")\n",
        "sns.scatterplot(data=X_minmax, x=\"alcohol\", y=\"malic_acid\", label=\"Minmaxed\")\n",
        "\n",
        "print(\"Minmax groups the data very tightly in contrast to regular normalisation which mostly just moves all the points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ5Ncd5cN-9z"
      },
      "source": [
        "We will now have a closer look at the data. Calculate for the un-normalized training data as well as for the two normalized versions of the training data\n",
        "\n",
        "- The average value in the column `avg(alcohol)`\n",
        "- The standard deviation in the column `std(alcohol)`\n",
        "- The minimum value in the column `min(alcohol)`\n",
        "- The maxmium value in the column `max(alcohol)`\n",
        "- The range in the column by subtracting the minimum of the maximum in the column `max(alcohol) - min(alcohol)`\n",
        "\n",
        "Compare the properties of the un-normalized training data with the normalized training data. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J3D06pyKQjGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050477b6-1fa1-4cb0-c5f9-a94f7bd9a289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Defaul: 12.971008403361346\n",
            "Average Normal: -1.1606028929694914e-15\n",
            "Average Minmax: 0.5107916850950908\n",
            "\n",
            "Standard Defaul: 0.8519751676953167\n",
            "Standard Normal: 1.0\n",
            "Standard Minmax: 0.22420399149876757\n",
            "\n",
            "Min Defaul: 11.03\n",
            "Min Normal: -2.278245278688087\n",
            "Min Minmax: 0.0\n",
            "\n",
            "Max Defaul: 14.83\n",
            "Max Normal: 2.181978615254039\n",
            "Max Minmax: 1.0\n",
            "\n",
            "Max - Min Defaul: 3.8000000000000007\n",
            "Max - Min Normal: 4.460223893942126\n",
            "Max - Min Minmax: 1.0\n",
            "\n",
            "\n",
            "As visible by the average, standardisation is centered around zero. We can also see that the sdt. dev. is 1 as per definition.\n",
            "The minmax ranges from 0 to 1 as per definition\n"
          ]
        }
      ],
      "source": [
        "def compare_stats(data_a, label_a, data_b, label_b, data_c, label_c):\n",
        "  print(f'Average {label_a}: {data_a.alcohol.mean()}')\n",
        "  print(f'Average {label_b}: {data_b.alcohol.mean()}')\n",
        "  print(f'Average {label_c}: {data_c.alcohol.mean()}')\n",
        "  print()\n",
        "  print(f'Standard {label_a}: {data_a.alcohol.std()}')\n",
        "  print(f'Standard {label_b}: {data_b.alcohol.std()}')\n",
        "  print(f'Standard {label_c}: {data_c.alcohol.std()}')\n",
        "  print()\n",
        "  print(f'Min {label_a}: {data_a.alcohol.min()}')\n",
        "  print(f'Min {label_b}: {data_b.alcohol.min()}')\n",
        "  print(f'Min {label_c}: {data_c.alcohol.min()}')\n",
        "  print()\n",
        "  print(f'Max {label_a}: {data_a.alcohol.max()}')\n",
        "  print(f'Max {label_b}: {data_b.alcohol.max()}')\n",
        "  print(f'Max {label_c}: {data_c.alcohol.max()}')\n",
        "  print()\n",
        "  print(f'Max - Min {label_a}: {data_a.alcohol.max() - data_a.alcohol.min()}')\n",
        "  print(f'Max - Min {label_b}: {data_b.alcohol.max() - data_b.alcohol.min()}')\n",
        "  print(f'Max - Min {label_c}: {data_c.alcohol.max() - data_c.alcohol.min()}')\n",
        "  print()\n",
        "\n",
        "compare_stats(X_train, \"Defaul\", X_norm, \"Normal\", X_minmax, \"Minmax\")\n",
        "print()\n",
        "print(\"As visible by the average, standardisation is centered around zero. We can also see that the sdt. dev. is 1 as per definition.\")\n",
        "print(\"The minmax ranges from 0 to 1 as per definition\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH7H07ZcSniv"
      },
      "source": [
        "## ðŸ“¢ **HAND-IN** ðŸ“¢: Report on Moodle whether you solved this task.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT3_BLJDl-0o"
      },
      "source": [
        "# TASK 3 (6 Points): Binning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7K4Cikz4aZE"
      },
      "source": [
        "The following list consists of the age of several people: \n",
        "```python\n",
        "[13, 15, 16, 18, 19, 20, 20, 21, 22, 22, 25, 25, 26, 26, 30, 33, 34, 35, 35, 35, 36, 37, 40, 42, 46, 53, 70]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsHmNGlW4aZE"
      },
      "source": [
        "### Task 3a: Equal-Width Binning\n",
        "Apply binning to the dataset using 3 equal-width bins. Smooth the data using the mean of the bins.\n",
        "\n",
        "Tips:\n",
        "1. Calculate the size of the bins\n",
        "2. Assign each value to the corresponding bin\n",
        "3. Calculate the mean per bin\n",
        "4. Replace each value by the mean of its bin\n",
        "\n",
        "__Solve this exercise by hand without using Python__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "a: [13, 15, 16, 18, 19, 20, 20, 21, 22, 22, 25, 25, 26, 26, 30]: 21.2\n",
        "b: [33, 34, 35, 35, 35, 36, 37, 40, 42, 46]: 37.3\n",
        "c: [53, 70]: 61.5\n",
        "\n",
        "a: [21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2, 21.2] \n",
        "b: [37.3, 37.3, 37.3, 37.3, 37.3, 37.3, 37.3, 37.3, 37.3, 37.3]\n",
        "c: [61.5, 61.5]\n",
        "```"
      ],
      "metadata": {
        "id": "bVNMPFmWNulp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UL9OUG44aZF"
      },
      "source": [
        "### Task 3b: Equal-Depth Binning\n",
        "\n",
        "Apply binning to the dataset using 3 equal-depth bins. Smooth the data using the mean of the bins. Explain the steps of your approach and give the final result.\n",
        "\n",
        "Tips:\n",
        "1. Calculate the number of elements per bin\n",
        "2. Assign each value to the corresponding bin\n",
        "3. Calculate the mean per bin\n",
        "4. Replace each value by the mean of its bin\n",
        "\n",
        "__Please solve this exercise by hand without using Python__ "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "a: [13, 15, 16, 18, 19, 20, 20, 21, 22]: 18.22: [18.22, 18.22, 18.22, 18.22, 18.22, 18.22, 18.22, 18.22, 18.22]\n",
        "b: [22, 25, 25, 26, 26, 30, 33, 34, 35]: 28.44: [28.44, 28.44, 28.44, 28.44, 28.44, 28.44, 28.44, 28.44, 28.44]\n",
        "c: [35, 35, 36, 37, 40, 42, 46, 53, 70]: 43.78: [43.78, 43.78, 43.78, 43.78, 43.78, 43.78, 43.78, 43.78, 43.78]\n",
        "```"
      ],
      "metadata": {
        "id": "xvrcSyGaOqIn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex21HuPTl_Qx"
      },
      "source": [
        "## ðŸ“¢ **HAND-IN** ðŸ“¢: Describe on Moodle the results of Exercise 3: \n",
        "\n",
        "* Copy the results of Exercise 3a and 3b to Moodle\n",
        "* Describe the differences between task 3a and task 3b\n",
        "* Describe situations when binning should be used and give a concrete example. Are there also circumstances in which binning should not be applied?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Equal-width binning only takes the range of data into account and is prone to outliers. Equal-depth binning simply creates equally large bins where outliers only affect numbers involving the sum of the bin.\n",
        "\n",
        "Depth bin averages are usually more closely together than width bins due to their weakness to outliers.\n",
        "\n",
        "Bins should not be used when the input data is non-numerical like with categorical data. Bins also have little benefit when the input set is insuffieciently large.\n",
        "\n",
        "\"Age\" is good data type to use bins with.\n",
        "```"
      ],
      "metadata": {
        "id": "ayyNuaWNPYO7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "558914ba93c675d10f9462c68c84c8e4fd6bd2548e0b0f568325ba1dc72cba58"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}